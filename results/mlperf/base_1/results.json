{
    "args": {
        "accuracy": false,
        "audit_conf": "audit.config",
        "backend": "pytorch",
        "count": null,
        "dataset": "coco-1024",
        "dataset_path": "/root/CM/repos/local/cache/3ae5be25ec254df3/install",
        "debug": false,
        "device": "cuda",
        "dtype": "fp16",
        "find_peak_performance": false,
        "ids_path": "/root/CM/repos/local/cache/3ae5be25ec254df3/install/sample_ids.txt",
        "latent_framework": "torch",
        "max_batchsize": 1,
        "max_latency": null,
        "model_name": "stable-diffusion-xl",
        "model_path": "/root/CM/repos/local/cache/a17af1c021c14272/stable_diffusion_fp16",
        "output": "/cm-mount/share/competition/mlperf/test_results/b69ecdacbd8e-reference-gpu-pytorch-v2.5.1-scc24-base_cu124/stable-diffusion-xl/offline/performance/run_1",
        "performance_sample_count": 5000,
        "profile": "stable-diffusion-xl-pytorch",
        "qps": null,
        "samples_per_query": 8,
        "scenario": "Offline",
        "threads": 1,
        "time": null,
        "user_conf": "/root/CM/repos/mlcommons@cm4mlops/script/generate-mlperf-inference-user-conf/tmp/a1da2ed6be3b452eba8257d54a69bfe4.conf"
    },
    "cmdline": "Namespace(dataset='coco-1024', dataset_path='/root/CM/repos/local/cache/3ae5be25ec254df3/install', profile='stable-diffusion-xl-pytorch', scenario='Offline', max_batchsize=1, threads=1, accuracy=False, find_peak_performance=False, backend='pytorch', model_name='stable-diffusion-xl', output='/cm-mount/share/competition/mlperf/test_results/b69ecdacbd8e-reference-gpu-pytorch-v2.5.1-scc24-base_cu124/stable-diffusion-xl/offline/performance/run_1', qps=None, model_path='/root/CM/repos/local/cache/a17af1c021c14272/stable_diffusion_fp16', dtype='fp16', device='cuda', latent_framework='torch', user_conf='/root/CM/repos/mlcommons@cm4mlops/script/generate-mlperf-inference-user-conf/tmp/a1da2ed6be3b452eba8257d54a69bfe4.conf', audit_conf='audit.config', ids_path='/root/CM/repos/local/cache/3ae5be25ec254df3/install/sample_ids.txt', time=None, count=None, debug=False, performance_sample_count=5000, max_latency=None, samples_per_query=8)",
    "runtime": "pytorch-SUT",
    "time": 1731365733,
    "version": "2.5.1+cu124"
}