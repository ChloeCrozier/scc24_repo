{
  "CM_SUT_CONFIG": {
    "8ee3099d0c84-reference-gpu-pytorch-v2.5.1-scc24-base_cu124": {
      "3d-unet-99": {
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        },
        "SingleStream": {
          "target_latency": 500
        }
      },
      "3d-unet-99.9": {
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        },
        "SingleStream": {
          "target_latency": 500
        }
      },
      "bert-99": {
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        },
        "SingleStream": {
          "target_latency": 1
        }
      },
      "bert-99.9": {
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        }
      },
      "gpt-j": {
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        },
        "SingleStream": {
          "target_latency": 500
        }
      },
      "llama2-70b-99": {
        "Offline": {
          "target_qps": 0.1
        },
        "Server": {
          "target_qps": 0.1
        },
        "SingleStream": {
          "target_latency": 2000
        }
      },
      "llama2-70b-99.9": {
        "Offline": {
          "target_qps": 0.1
        },
        "Server": {
          "target_qps": 0.1
        },
        "SingleStream": {
          "target_latency": 2000
        }
      },
      "resnet50": {
        "MultiStream": {
          "target_latency": 0.1
        },
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        },
        "SingleStream": {
          "target_latency": 0.1
        }
      },
      "retinanet": {
        "MultiStream": {
          "target_latency": 1
        },
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        },
        "SingleStream": {
          "target_latency": 1
        }
      },
      "sdxl": {
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        },
        "SingleStream": {
          "target_latency": 200
        }
      },
      "stable-diffusion-xl": {
        "Offline": {
          "target_qps": 0.05
        }
      }
    }
  },
  "CM_SUT_CONFIG_NAME": "8ee3099d0c84-reference-gpu-pytorch-v2.5.1-scc24-base_cu124",
  "CM_SUT_CONFIG_PATH": {
    "8ee3099d0c84-reference-gpu-pytorch-v2.5.1-scc24-base_cu124": "/root/CM/repos/local/cache/fc8a4bef07344a01/8ee3099d0c84/reference-implementation/gpu-device/pytorch-framework/framework-version-v2.5.1/scc24-base_cu124-config.yaml"
  },
  "RUN": {
    "Offline": {}
  },
  "cm_cuda_device_prop": {
    "CUDA driver version": "12.4",
    "CUDA runtime version": "12.4",
    "GPU Device ID": "0000:C1:00.0",
    "GPU Name": "NVIDIA A100-SXM4-40GB",
    "GPU compute capability": "8.0",
    "Global memory": "42285268992",
    "Max clock rate": "1410000 MHz",
    "Max dimension size of a grid size X": "2147483647",
    "Max dimension size of a grid size Y": "65535",
    "Max dimension size of a grid size Z": "65535",
    "Max dimension size of a thread block X": "1024",
    "Max dimension size of a thread block Y": "1024",
    "Max dimension size of a thread block Z": "64",
    "Maximum number of threads per block": "1024",
    "Maximum number of threads per multiprocessor": "2048",
    "Total amount of shared memory per block": "49152",
    "Total number of registers available per block": "65536",
    "Warp size": "32"
  },
  "cm_cuda_devices_prop": {
    "0": {
      "CUDA driver version": "12.4",
      "CUDA runtime version": "12.4",
      "GPU Device ID": "0000:01:00.0",
      "GPU Name": "NVIDIA A100-SXM4-40GB",
      "GPU compute capability": "8.0",
      "Global memory": "42285268992",
      "Max clock rate": "1410000 MHz",
      "Max dimension size of a grid size X": "2147483647",
      "Max dimension size of a grid size Y": "65535",
      "Max dimension size of a grid size Z": "65535",
      "Max dimension size of a thread block X": "1024",
      "Max dimension size of a thread block Y": "1024",
      "Max dimension size of a thread block Z": "64",
      "Maximum number of threads per block": "1024",
      "Maximum number of threads per multiprocessor": "2048",
      "Total amount of shared memory per block": "49152",
      "Total number of registers available per block": "65536",
      "Warp size": "32"
    },
    "1": {
      "CUDA driver version": "12.4",
      "CUDA runtime version": "12.4",
      "GPU Device ID": "0000:41:00.0",
      "GPU Name": "NVIDIA A100-SXM4-40GB",
      "GPU compute capability": "8.0",
      "Global memory": "42285268992",
      "Max clock rate": "1410000 MHz",
      "Max dimension size of a grid size X": "2147483647",
      "Max dimension size of a grid size Y": "65535",
      "Max dimension size of a grid size Z": "65535",
      "Max dimension size of a thread block X": "1024",
      "Max dimension size of a thread block Y": "1024",
      "Max dimension size of a thread block Z": "64",
      "Maximum number of threads per block": "1024",
      "Maximum number of threads per multiprocessor": "2048",
      "Total amount of shared memory per block": "49152",
      "Total number of registers available per block": "65536",
      "Warp size": "32"
    },
    "2": {
      "CUDA driver version": "12.4",
      "CUDA runtime version": "12.4",
      "GPU Device ID": "0000:81:00.0",
      "GPU Name": "NVIDIA A100-SXM4-40GB",
      "GPU compute capability": "8.0",
      "Global memory": "42285268992",
      "Max clock rate": "1410000 MHz",
      "Max dimension size of a grid size X": "2147483647",
      "Max dimension size of a grid size Y": "65535",
      "Max dimension size of a grid size Z": "65535",
      "Max dimension size of a thread block X": "1024",
      "Max dimension size of a thread block Y": "1024",
      "Max dimension size of a thread block Z": "64",
      "Maximum number of threads per block": "1024",
      "Maximum number of threads per multiprocessor": "2048",
      "Total amount of shared memory per block": "49152",
      "Total number of registers available per block": "65536",
      "Warp size": "32"
    },
    "3": {
      "CUDA driver version": "12.4",
      "CUDA runtime version": "12.4",
      "GPU Device ID": "0000:C1:00.0",
      "GPU Name": "NVIDIA A100-SXM4-40GB",
      "GPU compute capability": "8.0",
      "Global memory": "42285268992",
      "Max clock rate": "1410000 MHz",
      "Max dimension size of a grid size X": "2147483647",
      "Max dimension size of a grid size Y": "65535",
      "Max dimension size of a grid size Z": "65535",
      "Max dimension size of a thread block X": "1024",
      "Max dimension size of a thread block Y": "1024",
      "Max dimension size of a thread block Z": "64",
      "Maximum number of threads per block": "1024",
      "Maximum number of threads per multiprocessor": "2048",
      "Total amount of shared memory per block": "49152",
      "Total number of registers available per block": "65536",
      "Warp size": "32"
    }
  },
  "cm_cuda_num_devices": 4,
  "docker": {},
  "mlperf-inference-implementation": {
    "script_id": "app-mlperf-inference,d775cac873ee4231:reference,sdxl,pytorch,cuda,test,r4.1-dev_default,float16,offline"
  },
  "mlperf_inference_run_cmd": "cm run script --tags=app,mlperf,inference,generic,_reference,_sdxl,_pytorch,_cuda,_test,_r4.1-dev_default,_float16,_offline --quiet=true --env.CM_QUIET=yes --env.CM_MLPERF_IMPLEMENTATION=reference --env.CM_MLPERF_MODEL=sdxl --env.CM_MLPERF_RUN_STYLE=test --env.CM_MLPERF_SKIP_SUBMISSION_GENERATION=False --env.CM_DOCKER_PRIVILEGED_MODE=True --env.CM_MLPERF_SUBMISSION_SYSTEM_TYPE=datacenter --env.CM_MLPERF_DEVICE=cuda --env.CM_MLPERF_USE_DOCKER=True --env.CM_MLPERF_BACKEND=pytorch --env.CM_MLPERF_MODEL_PRECISION=float16 --env.CM_MLPERF_LOADGEN_SCENARIO=Offline --env.CM_MLPERF_FIND_PERFORMANCE_MODE=yes --env.CM_MLPERF_LOADGEN_ALL_MODES=no --env.CM_MLPERF_LOADGEN_MODE=performance --env.CM_MLPERF_RESULT_PUSH_TO_GITHUB=False --env.CM_MLPERF_INFERENCE_VERSION=4.1-dev --env.CM_RUN_MLPERF_INFERENCE_APP_DEFAULTS=r4.1-dev_default --env.CM_MLPERF_SUBMISSION_GENERATION_STYLE=short --env.CM_MLPERF_SUT_NAME_RUN_CONFIG_SUFFIX4=scc24-base --env.CM_DOCKER_IMAGE_NAME=scc24-reference --env.CM_MLPERF_INFERENCE_SOURCE_VERSION=4.1.23 --env.CM_MLPERF_LAST_RELEASE=v4.0 --env.CM_TMP_CURRENT_PATH=/share/competition/mlperf --env.CM_TMP_PIP_VERSION_STRING= --env.CM_MODEL=sdxl --env.CM_MLPERF_LOADGEN_COMPLIANCE=no --env.CM_MLPERF_LOADGEN_EXTRA_OPTIONS= --env.CM_MLPERF_LOADGEN_SCENARIOS,=Offline --env.CM_MLPERF_LOADGEN_MODES,=performance --env.OUTPUT_BASE_DIR=/share/competition/mlperf --env.CM_OUTPUT_FOLDER_NAME=test_results --add_deps_recursive.get-mlperf-inference-results-dir.tags=_version.r4_1-dev --add_deps_recursive.get-mlperf-inference-submission-dir.tags=_version.r4_1-dev --add_deps_recursive.mlperf-inference-nvidia-scratch-space.tags=_version.r4_1-dev --add_deps_recursive.submission-checker.tags=_short-run --add_deps_recursive.coco2014-preprocessed.tags=_size.50,_with-sample-ids --add_deps_recursive.coco2014-dataset.tags=_size.50,_with-sample-ids --add_deps_recursive.nvidia-preprocess-data.extra_cache_tags=scc24-base --v=False --print_env=False --print_deps=False --dump_version_info=True --env.OUTPUT_BASE_DIR=/cm-mount/share/competition/mlperf --env.CM_MLPERF_INFERENCE_SUBMISSION_DIR=/home/cmuser/CM/repos/local/cache/662b8a42bd3c415e/mlperf-inference-submission",
  "os_uname_all": "Linux 8ee3099d0c84 4.18.0-553.22.1.el8_10.x86_64 #1 SMP Wed Sep 25 09:20:43 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux",
  "os_uname_machine": "x86_64"
}

